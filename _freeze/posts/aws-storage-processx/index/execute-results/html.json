{
  "hash": "f41f8ceb7589fd40825af6e24aaa5fe8",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Syncing files to aws with R\"\nauthor: \"al\"\ndate: \"2024-05-23\"\ndate-modified: \"2024-05-23\"\ncategories: [news, assets]\nimage: \"image.jpg\"\nparams:\n  repo_owner: \"NewGraphEnvironment\"\n  repo_name: \"new_graphiti\"\nformat: \n  html:\n    code-fold: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = \"100%\")\noptions(scipen=999)\noptions(knitr.kable.NA = '--') #'--'\noptions(knitr.kable.NAN = '--')\n```\n:::\n\n\nInspired by https://blog.djnavarro.net/posts/2022-03-17_using-aws-s3-in-r/ by [Danielle Navarro](https://github.com/djnavarro).\n\n\nQuick post to document where I got to with syncing files to aws with R. Didn't love the `aws.s3::sync` function because\nfrom what I could tell I could not tell it to delete files if they were not present locally or in a bucket (I could be wrong). \nSo... figured why not just call the `aws` command line tool from R. `processx` is an insane package that might be the mother of all\npackages. It allows you to run command line tools from R wiwht flexibility for some things like setting the  directory \nwhere the command is called in the function (big deal as far as I can tell). \n\n<br>\n\nWe need to set up our `aws` account online. The blog above covers that I believe (I struggled through it a long time ago). I should use a `~/.aws/credentials` file but don't yet.  I have my credentials in my `~/.Renviron` file as well as in my `~/.bash_profile`. They are:\n\n    AWS_ACCESS_KEY_ID='my_key'\n    AWS_DEFAULT_REGION='my_region'\n    AWS_SECRET_ACCESS_KEY='my_secret_key'\n\n\n\nLet's us `aws.s3` to make a bucket and see what we are doing. Make a bucket called `test-02240523-01`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(aws.s3)\nlibrary(processx)\n```\n:::\n\n\nSee our buckets\n\n\n::: {.cell}\n\n```{.r .cell-code}\naws.s3::bucketlist()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Bucket             CreationDate\n1  23cog 2023-03-17T00:07:12.000Z\n```\n\n\n:::\n:::\n\n\nMake a new bucket\n\n\n::: {.cell}\n\n```{.r .cell-code}\naws.s3::put_bucket(\"test-20240523-01\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\nWe build a little wrapper function to help us debug issues.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsys_call <- function(){\n  result <- tryCatch({\n    processx::run(\n      command,\n      args = args,\n      echo = TRUE,            # Print the command output live\n      wd = working_directory, # Set the working directory\n      spinner = TRUE,         # Show a spinner\n      timeout = 60            # Timeout after 60 seconds\n    )\n  }, error = function(e) {\n    # Handle errors: e.g., print a custom error message\n    cat(\"An error occurred: \", e$message, \"\\n\")\n    NULL  # Return NULL or another appropriate value\n  })\n  \n  # Check if the command was successful\n  if (!is.null(result)) {\n    cat(\"Exit status:\", result$status, \"\\n\")\n    cat(\"Output:\\n\", result$stdout)\n  } else {\n    cat(\"Failed to execute the command properly.\\n\")\n  }\n}\n```\n:::\n\n\n<br>\n\nThen we specify our command and arguments. To achieve the desired behavior of including only files in the `assets/*` directory, you need to combine the --exclude and --include flags appropriately.:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommand <- \"aws\"\nargs <- c('s3', 'sync', '.', 's3://test-20240523-01', '--delete', '--exclude', '*', '--include', 'assets/*')\nworking_directory = '.' #we could just remove from funciton to get the current wd but its nice to have so we leave\n```\n:::\n\n\nNow lets put a tester file in our directory and sync it to our bucket. We will remove it later to test if it is removed on sync.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile.create('assets/test.txt')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\n\n\nRun our little function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsys_call()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExit status: 0 \nOutput:\n \n```\n\n\n:::\n:::\n\n\nThen we can list our bucket contents and capture them\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- aws.s3::get_bucket_df('test-20240523-01') \n```\n:::\n\n\nNow we will remove `test.txt`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile.remove('assets/test.txt')\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\n```\n\n\n:::\n:::\n\n\nNow we sync again \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsys_call()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nExit status: 0 \nOutput:\n \n```\n\n\n:::\n:::\n\n\nList our bucket contents and capture them again\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2 <- aws.s3::get_bucket_df('test-20240523-01') \n```\n:::\n\nCompare the two dataframes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwaldo::compare(t$bucket, t2$bucket)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nâœ” No differences\n```\n\n\n:::\n:::\n\n\nSuccess!! Lets delete the bucket\n\n\n::: {.cell}\n\n```{.r .cell-code}\n  result <- tryCatch({\n    aws.s3::delete_bucket(\"test-20240523-01\")\n  }, error = function(e) {\n    # Handle errors: e.g., print a custom error message\n    cat(\"An error occurred: \", e$message, \"\\n\")\n    NULL  # Return NULL or another appropriate value\n  })\n```\n:::\n\n\nWon't let me do it... Think it is because we have used the command line tool to manage it... not sure.  Lets use the cli\n\n\n::: {.cell}\n\n```{.r .cell-code}\nargs <- c('s3', 'rb', 's3://test-20240523-01', '--force')\nsys_call()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfatal error: An error occurred (NoSuchBucket) when calling the ListObjectsV2 operation: The specified bucket does not exist\n\nremove_bucket failed: Unable to delete all objects in the bucket, bucket will not be deleted.\nAn error occurred:  System command 'aws' failed \nFailed to execute the command properly.\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}