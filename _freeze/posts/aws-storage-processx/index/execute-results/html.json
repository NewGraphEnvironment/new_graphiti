{
  "hash": "24d79149fedc79a9d84b7c46171e199b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Syncing files to aws with R\"\nauthor: \"al\"\ndate: \"2024-05-23\"\ndate-modified: \"2024-05-23\"\ncategories: [news, assets]\nimage: \"image.jpg\"\nparams:\n  repo_owner: \"NewGraphEnvironment\"\n  repo_name: \"new_graphiti\"\nformat: \n  html:\n    code-fold: true\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nknitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = \"100%\")\noptions(scipen=999)\noptions(knitr.kable.NA = '--') #'--'\noptions(knitr.kable.NAN = '--')\n```\n:::\n\n\nInspired by https://blog.djnavarro.net/posts/2022-03-17_using-aws-s3-in-r/ by [Danielle Navarro](https://github.com/djnavarro).\n\n\nInterestingly none of this works when published because it will be built there with github actions. Anyway,\nthis renders locally and that is good enough for now.\n\n\n\nQuick post to document where I got to with syncing files to aws with R. Didn't love the `aws.s3::sync` function because\nfrom what I could tell I could not tell it to delete files if they were not present locally or in a bucket (I could be wrong). \nSo... figured why not just call the `aws` command line tool from R. `processx` is an insane package that might be the mother of all\npackages. It allows you to run command line tools from R wiwht flexibility for some things like setting the  directory \nwhere the command is called in the function (big deal as far as I can tell). \n\n\nWe need to set up our `aws` account online. The blog above covers that I believe (I struggled through it a long time ago). I should use a `~/.aws/credentials` file but don't yet.  I have my credentials in my `~/.Renviron` file as well as in my `~/.bash_profile`. They are:\n\n    AWS_ACCESS_KEY_ID='my_key'\n    AWS_DEFAULT_REGION='my_region'\n    AWS_SECRET_ACCESS_KEY='my_secret_key'\n\nLet's us `aws.s3` to make a bucket and see what we are doing. Make a bucket called `test-02240523-01`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(aws.s3)\nlibrary(processx)\n```\n:::\n\n\nSee our buckets\n\n\n::: {.cell}\n\n```{.r .cell-code}\naws.s3::bucketlist()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  Bucket             CreationDate\n1  23cog 2023-03-17T00:07:12.000Z\n```\n\n\n:::\n:::\n\n\nMake a new bucket\n\n\n::: {.cell}\n\n```{.r .cell-code}\naws.s3::put_bucket(\"test-20240523-01\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\nWe build a little wrapper function to help us debug issues.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsys_call <- function(){\n  result <- tryCatch({\n    processx::run(\n      command,\n      args = args,\n      echo = TRUE,            # Print the command output live\n      wd = working_directory, # Set the working directory\n      spinner = TRUE,         # Show a spinner\n      timeout = 60            # Timeout after 60 seconds\n    )\n  }, error = function(e) {\n    # Handle errors: e.g., print a custom error message\n    cat(\"An error occurred: \", e$message, \"\\n\")\n    NULL  # Return NULL or another appropriate value\n  })\n  \n  # Check if the command was successful\n  if (!is.null(result)) {\n    cat(\"Exit status:\", result$status, \"\\n\")\n    cat(\"Output:\\n\", result$stdout)\n  } else {\n    cat(\"Failed to execute the command properly.\\n\")\n  }\n}\n```\n:::\n\n\n<br>\n\nThen we specify our command and arguments. To achieve the desired behavior of including only files in the `assets/*` directory, you need to combine the --exclude and --include flags appropriately.:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncommand <- \"aws\"\nargs <- c('s3', 'sync', '.', 's3://test-20240523-01', '--delete', '--exclude', '*', '--include', 'posts/*')\nworking_directory = here::here() #we could just remove from funciton to get the current wd but its nice to have so we leave\n```\n:::\n\n\nNow lets put a tester file in our directory and sync it to our bucket. We will remove it later to test if it is removed on sync.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile.create(here::here('posts/test.txt'))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\n\n\nRun our little function\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsys_call()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCompleted 237 Bytes/492.0 KiB (2.9 KiB/s) with 10 file(s) remaining\nupload: posts/_metadata.yml to s3://test-20240523-01/posts/_metadata.yml\nCompleted 237 Bytes/492.0 KiB (2.9 KiB/s) with 9 file(s) remaining\nupload: posts/test.txt to s3://test-20240523-01/posts/test.txt    \nCompleted 237 Bytes/492.0 KiB (2.9 KiB/s) with 8 file(s) remaining\nCompleted 2.0 KiB/492.0 KiB (11.3 KiB/s) with 8 file(s) remaining \nupload: posts/logos-equipment/index.qmd to s3://test-20240523-01/posts/logos-equipment/index.qmd\nCompleted 2.0 KiB/492.0 KiB (11.3 KiB/s) with 7 file(s) remaining\nCompleted 3.6 KiB/492.0 KiB (20.5 KiB/s) with 7 file(s) remaining\nupload: posts/snakecase/index.qmd to s3://test-20240523-01/posts/snakecase/index.qmd\nCompleted 3.6 KiB/492.0 KiB (20.5 KiB/s) with 6 file(s) remaining\nCompleted 7.5 KiB/492.0 KiB (40.8 KiB/s) with 6 file(s) remaining\nupload: posts/aws-storage-processx/image.jpg to s3://test-20240523-01/posts/aws-storage-processx/image.jpg\nCompleted 7.5 KiB/492.0 KiB (40.8 KiB/s) with 5 file(s) remaining\nCompleted 12.5 KiB/492.0 KiB (65.5 KiB/s) with 5 file(s) remaining\nupload: posts/aws-storage-processx/index.qmd to s3://test-20240523-01/posts/aws-storage-processx/index.qmd\nCompleted 12.5 KiB/492.0 KiB (65.5 KiB/s) with 4 file(s) remaining\nCompleted 17.5 KiB/492.0 KiB (91.7 KiB/s) with 4 file(s) remaining\nupload: posts/aws-storage-processx/index.rmarkdown to s3://test-20240523-01/posts/aws-storage-processx/index.rmarkdown\nCompleted 17.5 KiB/492.0 KiB (91.7 KiB/s) with 3 file(s) remaining\nCompleted 22.6 KiB/492.0 KiB (112.5 KiB/s) with 3 file(s) remaining\nupload: posts/snakecase/thumbnail.jpg to s3://test-20240523-01/posts/snakecase/thumbnail.jpg\nCompleted 22.6 KiB/492.0 KiB (112.5 KiB/s) with 2 file(s) remaining\nCompleted 63.3 KiB/492.0 KiB (193.1 KiB/s) with 2 file(s) remaining\nupload: posts/logos-equipment/image.jpg to s3://test-20240523-01/posts/logos-equipment/image.jpg\nCompleted 63.3 KiB/492.0 KiB (193.1 KiB/s) with 1 file(s) remaining\nCompleted 319.3 KiB/492.0 KiB (826.2 KiB/s) with 1 file(s) remaining\nCompleted 492.0 KiB/492.0 KiB (641.5 KiB/s) with 1 file(s) remaining\nupload: posts/snakecase/all.jpeg to s3://test-20240523-01/posts/snakecase/all.jpeg\nExit status: 0 \nOutput:\n Completed 237 Bytes/492.0 KiB (2.9 KiB/s) with 10 file(s) remaining\nupload: posts/_metadata.yml to s3://test-20240523-01/posts/_metadata.yml\nCompleted 237 Bytes/492.0 KiB (2.9 KiB/s) with 9 file(s) remaining\nupload: posts/test.txt to s3://test-20240523-01/posts/test.txt    \nCompleted 237 Bytes/492.0 KiB (2.9 KiB/s) with 8 file(s) remaining\nCompleted 2.0 KiB/492.0 KiB (11.3 KiB/s) with 8 file(s) remaining \nupload: posts/logos-equipment/index.qmd to s3://test-20240523-01/posts/logos-equipment/index.qmd\nCompleted 2.0 KiB/492.0 KiB (11.3 KiB/s) with 7 file(s) remaining\nCompleted 3.6 KiB/492.0 KiB (20.5 KiB/s) with 7 file(s) remaining\nupload: posts/snakecase/index.qmd to s3://test-20240523-01/posts/snakecase/index.qmd\nCompleted 3.6 KiB/492.0 KiB (20.5 KiB/s) with 6 file(s) remaining\nCompleted 7.5 KiB/492.0 KiB (40.8 KiB/s) with 6 file(s) remaining\nupload: posts/aws-storage-processx/image.jpg to s3://test-20240523-01/posts/aws-storage-processx/image.jpg\nCompleted 7.5 KiB/492.0 KiB (40.8 KiB/s) with 5 file(s) remaining\nCompleted 12.5 KiB/492.0 KiB (65.5 KiB/s) with 5 file(s) remaining\nupload: posts/aws-storage-processx/index.qmd to s3://test-20240523-01/posts/aws-storage-processx/index.qmd\nCompleted 12.5 KiB/492.0 KiB (65.5 KiB/s) with 4 file(s) remaining\nCompleted 17.5 KiB/492.0 KiB (91.7 KiB/s) with 4 file(s) remaining\nupload: posts/aws-storage-processx/index.rmarkdown to s3://test-20240523-01/posts/aws-storage-processx/index.rmarkdown\nCompleted 17.5 KiB/492.0 KiB (91.7 KiB/s) with 3 file(s) remaining\nCompleted 22.6 KiB/492.0 KiB (112.5 KiB/s) with 3 file(s) remaining\nupload: posts/snakecase/thumbnail.jpg to s3://test-20240523-01/posts/snakecase/thumbnail.jpg\nCompleted 22.6 KiB/492.0 KiB (112.5 KiB/s) with 2 file(s) remaining\nCompleted 63.3 KiB/492.0 KiB (193.1 KiB/s) with 2 file(s) remaining\nupload: posts/logos-equipment/image.jpg to s3://test-20240523-01/posts/logos-equipment/image.jpg\nCompleted 63.3 KiB/492.0 KiB (193.1 KiB/s) with 1 file(s) remaining\nCompleted 319.3 KiB/492.0 KiB (826.2 KiB/s) with 1 file(s) remaining\nCompleted 492.0 KiB/492.0 KiB (641.5 KiB/s) with 1 file(s) remaining\nupload: posts/snakecase/all.jpeg to s3://test-20240523-01/posts/snakecase/all.jpeg\n```\n\n\n:::\n:::\n\n\nThen we can list our bucket contents and capture them\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- aws.s3::get_bucket_df('test-20240523-01') \n```\n:::\n\n\nNow we will remove `test.txt`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfile.remove(here::here('posts/test.txt'))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] TRUE\n```\n\n\n:::\n:::\n\n\nNow we sync again \n\n\n::: {.cell}\n\n```{.r .cell-code}\nsys_call()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndelete: s3://test-20240523-01/posts/test.txt\nExit status: 0 \nOutput:\n delete: s3://test-20240523-01/posts/test.txt\n```\n\n\n:::\n:::\n\n\nList our bucket contents and capture them again\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt2 <- aws.s3::get_bucket_df('test-20240523-01') \n```\n:::\n\nCompare the two dataframes\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwaldo::compare(t$Key, t2$Key)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n     old                             | new                                \n [7] \"posts/snakecase/all.jpeg\"      | \"posts/snakecase/all.jpeg\"      [7]\n [8] \"posts/snakecase/index.qmd\"     | \"posts/snakecase/index.qmd\"     [8]\n [9] \"posts/snakecase/thumbnail.jpg\" | \"posts/snakecase/thumbnail.jpg\" [9]\n[10] \"posts/test.txt\"                -                                    \n```\n\n\n:::\n:::\n\n\nSuccess!! Lets delete the bucket\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# run_with_error_handling <- function(call_expr) {\n#   result <- tryCatch({\n#     eval(call_expr)\n#   }, error = function(e) {\n#     # Handle errors: e.g., print a custom error message\n#     cat(\"An error occurred: \", e$message, \"\\n\")\n#     NULL  # Return NULL or another appropriate value\n#   })\n#   \n#   if (is.null(result)) {\n#     cat(\"The operation failed.\\n\")\n#   } else {\n#     if (is.logical(result) && result) {\n#       cat(\"The operation succeeded.\\n\")\n#     } else {\n#       cat(\"The operation completed but did not return a success indicator.\\n\")\n#       print(result)  # Print the result for further inspection\n#     }\n#   }\n# }\n# \n# # Example usage with aws.s3::delete_bucket\n# run_with_error_handling(quote(aws.s3::delete_bucket(\"test-20240523-01\")))\n\n# Example usage with another call\n# run_with_error_handling(quote(another_function_call(args)))\naws.s3::delete_bucket(\"test-20240523-01\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] FALSE\nattr(,\"x-amz-request-id\")\n[1] \"54VPM699PYPQ4B12\"\nattr(,\"x-amz-id-2\")\n[1] \"0P3w/yPlADBu1yNMKc3xb8VE41ryyCBoYbgJLWp9f9BXBQv03kLLcDTg6x/0Hx4BWXcDbtbVCxQ=\"\nattr(,\"content-type\")\n[1] \"application/xml\"\nattr(,\"transfer-encoding\")\n[1] \"chunked\"\nattr(,\"date\")\n[1] \"Thu, 23 May 2024 22:45:06 GMT\"\nattr(,\"server\")\n[1] \"AmazonS3\"\n```\n\n\n:::\n:::\n\n\nWon't let me do it... Think it is because we have used the command line tool to manage it... not sure.  Lets use the cli\n\n\n::: {.cell}\n\n```{.r .cell-code}\nargs <- c('s3', 'rb', 's3://test-20240523-01', '--force')\nsys_call()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndelete: s3://test-20240523-01/posts/aws-storage-processx/index.rmarkdown\ndelete: s3://test-20240523-01/posts/aws-storage-processx/index.qmd\ndelete: s3://test-20240523-01/posts/logos-equipment/index.qmd\ndelete: s3://test-20240523-01/posts/logos-equipment/image.jpg\ndelete: s3://test-20240523-01/posts/snakecase/thumbnail.jpg\ndelete: s3://test-20240523-01/posts/snakecase/index.qmd\ndelete: s3://test-20240523-01/posts/aws-storage-processx/image.jpg\ndelete: s3://test-20240523-01/posts/_metadata.yml\ndelete: s3://test-20240523-01/posts/snakecase/all.jpeg\nremove_bucket: test-20240523-01\nExit status: 0 \nOutput:\n delete: s3://test-20240523-01/posts/aws-storage-processx/index.rmarkdown\ndelete: s3://test-20240523-01/posts/aws-storage-processx/index.qmd\ndelete: s3://test-20240523-01/posts/logos-equipment/index.qmd\ndelete: s3://test-20240523-01/posts/logos-equipment/image.jpg\ndelete: s3://test-20240523-01/posts/snakecase/thumbnail.jpg\ndelete: s3://test-20240523-01/posts/snakecase/index.qmd\ndelete: s3://test-20240523-01/posts/aws-storage-processx/image.jpg\ndelete: s3://test-20240523-01/posts/_metadata.yml\ndelete: s3://test-20240523-01/posts/snakecase/all.jpeg\nremove_bucket: test-20240523-01\n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}