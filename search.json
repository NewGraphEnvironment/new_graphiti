[
  {
    "objectID": "posts/aws-storage-permissions/index.html",
    "href": "posts/aws-storage-permissions/index.html",
    "title": "Setting aws bucket permissions with R",
    "section": "",
    "text": "Here we will set up an s3 bucket with a policy that allows the public to read from the bucket, but not from a specific directory, and allows a particular aws_account_id to write to the bucket. Although we are stoked on the s3fs package for working with s3 buckets, we will use the paws package more than perhaps necessary here - only to learn about how it all works. Seems like s3fs is the way to go for common moves but paws is the ‚Äúmom‚Äù providing the structure and guidance to that package.\n\n\nCode\nlibrary(paws)\nlibrary(here)\n\n\nhere() starts at /Users/airvine/Projects/repo/new_graphiti\n\n\nCode\nlibrary(jsonlite)\nlibrary(stringr)\nlibrary(s3fs)\n\n\nList our current buckets\n\n\nCode\ns3 &lt;- paws::s3()\ns3$list_buckets()\n\n\n$Buckets\n$Buckets[[1]]\n$Buckets[[1]]$Name\n[1] \"23cog\"\n\n$Buckets[[1]]$CreationDate\n[1] \"2023-03-17 00:07:12 GMT\"\n\n\n\n$Owner\n$Owner$DisplayName\n[1] \"al\"\n\n$Owner$ID\n[1] \"f5267b02e31758d1efea79b4eaef5d0423efb3e6a54ab869dc860bcc68ebae2d\"\n\n\n\nCreate Bucket\nLet‚Äôs create a bucket called the same name as this repository.\n\n\nCode\nmy_bucket_name &lt;- basename(here::here()) |&gt; \n  stringr::str_replace_all(\"_\", \"-\") \n\nbucket_path &lt;- s3fs::s3_path(my_bucket_name)\n\ns3$create_bucket(Bucket = my_bucket_name,\n  CreateBucketConfiguration = list(\n    LocationConstraint = Sys.getenv(\"AWS_DEFAULT_REGION\")\n  ))\n\n\n$Location\n[1] \"http://new-graphiti.s3.amazonaws.com/\"\n\n\n\n\nAdd the policy to the bucket.\n\nImportant - First we need to allow ‚Äúnew public policies‚Äù to be added to the bucket.\n\n\n\nCode\ns3$delete_public_access_block(\n  Bucket = my_bucket_name\n)\n\n\nlist()\n\n\n\nWrite the policy for the bucket Here is a function to make a generic policy for an s3 bucket that allows public to read from the bucket, but not from a specific directory, and allows a particular aws_account_id to write to the bucket. Plus + it allows you to provide Presigned URLs so we can provide temporary access to private objects without having to change the overall bucket or object permissions.\n\n\n\nCode\naws_policy_write &lt;- function(bucket_name, bucket_dir_private, aws_account_id, write_json = FALSE, dir_output = \"policy\", file_name = \"policy.json\") {\n  policy &lt;- list(\n    Statement = list(\n      list(\n        Effect = \"Allow\",\n        Principal = \"*\",\n        Action = \"s3:GetObject\",\n        Resource = paste0(\"arn:aws:s3:::\", bucket_name, \"/*\")\n      ),\n      list(\n        Effect = \"Deny\",\n        Principal = \"*\",\n        Action = \"s3:GetObject\",\n        Resource = paste0(\"arn:aws:s3:::\", bucket_name, \"/\", bucket_dir_private, \"/*\"),\n        Condition = list(\n          StringNotEquals = list(\n            \"aws:UserAgent\" = c(\"S3Console\", \"paws-storage\")\n          )\n        )\n      ),\n      list(\n        Effect = \"Allow\",\n        Principal = list(AWS = paste0(\"arn:aws:iam::\", aws_account_id, \":root\")),\n        Action = c(\"s3:DeleteObject\", \"s3:PutObject\"),\n        Resource = paste0(\"arn:aws:s3:::\", bucket_name, \"/*\")\n      )\n    )\n  )\n  \n  json_policy &lt;- jsonlite::toJSON(policy, pretty = TRUE, auto_unbox = TRUE)\n  \n  if (write_json) {\n  dir.create(dir_output, showWarnings = FALSE)\n  output_path &lt;- file.path(dir_output, file_name)\n  write(json_policy, file = output_path)\n    message(\"Policy written to \", output_path)\n  }else{\n    return(json_policy)\n  }\n}\n\n\nNow we can write the policy to the bucket.\n\n\nCode\nmy_policy &lt;- aws_policy_write(bucket_name = my_bucket_name, \n                         bucket_dir_private = \"private\", \n                         aws_account_id = Sys.getenv(\"AWS_ACCOUNT_ID\"),\n                         write_json = FALSE\n                         )\n\ns3$put_bucket_policy(\n  Bucket = my_bucket_name,\n  Policy = my_policy,\n  ExpectedBucketOwner = Sys.getenv(\"AWS_ACCOUNT_ID\")\n)\n\n\nlist()\n\n\nCheck the policy was added correctly.\n\n\nCode\n# this is cool\ns3$get_bucket_policy(my_bucket_name)\n\n\n$Policy\n[1] \"{\\\"Version\\\":\\\"2008-10-17\\\",\\\"Statement\\\":[{\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":\\\"*\\\",\\\"Action\\\":\\\"s3:GetObject\\\",\\\"Resource\\\":\\\"arn:aws:s3:::new-graphiti/*\\\"},{\\\"Effect\\\":\\\"Deny\\\",\\\"Principal\\\":\\\"*\\\",\\\"Action\\\":\\\"s3:GetObject\\\",\\\"Resource\\\":\\\"arn:aws:s3:::new-graphiti/private/*\\\",\\\"Condition\\\":{\\\"StringNotEquals\\\":{\\\"aws:UserAgent\\\":[\\\"S3Console\\\",\\\"paws-storage\\\"]}}},{\\\"Effect\\\":\\\"Allow\\\",\\\"Principal\\\":{\\\"AWS\\\":\\\"arn:aws:iam::414155577829:root\\\"},\\\"Action\\\":[\\\"s3:DeleteObject\\\",\\\"s3:PutObject\\\"],\\\"Resource\\\":\\\"arn:aws:s3:::new-graphiti/*\\\"}]}\"\n\n\n\n\nAdd some files to the bucket\nFirst we add a photo to the main bucket. Going to use s3fs for this since I haven‚Äôt actually done just one file yet‚Ä¶ We are using the here package to get the path to the image due to rendering complexities.\n\n\nCode\ns3fs::s3_file_copy(\n  path = paste0(here::here(), \"/posts/aws-storage-permissions/image.jpg\"),\n  bucket_path\n)\n\n\n[1] \"s3://new-graphiti/image.jpg\"\n\n\nThen we add one to the private directory.\n\n\nCode\ns3fs::s3_dir_create(\n  path = paste0(bucket_path, \"/private\")\n)\n\n\n[1] \"s3://new-graphiti/private\"\n\n\nCode\ns3fs::s3_file_copy(\n  path = paste0(here::here(), \"/posts/aws-storage-permissions/image.jpg\"),\n  paste0(bucket_path, \"/private\")\n)\n\n\n[1] \"s3://new-graphiti/private/image.jpg\"\n\n\n\n\nAccess the bucket\nLet‚Äôs see if we can add the images to this post.\nCreate the paths to the images.\n\n\nCode\n# s3fs::s3_dir_info(bucket_path, recurse = TRUE)\nimage_path &lt;- paste0(\"https://\", my_bucket_name, \".s3.amazonaws.com/image.jpg\")\nimage_path_private &lt;- paste0(\"https://\", my_bucket_name, \".s3.amazonaws.com/private/image.jpg\")\n\n\nAccess the public image.\n\n\nCode\nknitr::include_graphics(image_path)\n\n\n\n\n\n\n\n\n\nGood to go.\nAnd now access the private image.\n\n\nCode\nknitr::include_graphics(image_path_private)\n\n\n\n\n\n\n\n\n\nüí£ Jackpot! We have the image in the bucket but can‚Äôt access them from the post.\n\n\nCode\n# Provide temporary access to an object\n# Can't get this to work yet so will come back to it.\nknitr::include_graphics(\n  s3fs::s3_file_url(\n    paste0(bucket_path, \"/private\", \"/image.jpg\")\n  )\n)\n\n\n\n\nCode\n# Delete the bucket\n# Burn down the bucket üî•.  If we try to use `s3$delete_bucket(Bucket = my_bucket_name)` we will get an error because the \n# bucket is not empty. `s3fs::s3_bucket_delete(bucket_path)` works fine though.\n\ns3fs::s3_bucket_delete(bucket_path)"
  },
  {
    "objectID": "posts/aws-storage-processx/index.html",
    "href": "posts/aws-storage-processx/index.html",
    "title": "Syncing files to aws with R",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = \"100%\")\noptions(scipen=999)\noptions(knitr.kable.NA = '--') #'--'\noptions(knitr.kable.NAN = '--')\n\n\nInspired by https://blog.djnavarro.net/posts/2022-03-17_using-aws-s3-in-r/ by Danielle Navarro.\nNote to self - /Users/airvine/Projects/repo/new_graphiti/_freeze/posts/aws-storage-processx/index/execute-results/html.json is created when I render this document. This seems to be what is published to website after 1. the github_actions workflow is run to generate the gh-pages branch (on github runner) 2. the site is published with gitpages from github.\n‚ÄúQuick‚Äù post to document where I got to with syncing files to aws with R. Didn‚Äôt love the aws.s3::sync function because from what I could tell I could not tell it to delete files if they were not present locally or in a bucket (I could be wrong).\nThen climbed into s3fs which mirrors the fs package and seems a bit more user friendly than the aws.s3 package for managing files. It is created by Dyfan Jones who also is the top contributor to paws!! He seems like perhaps as much of a beast as one of the contributors to s3fs who is Scott Chamberlain.\nFor the sync issue figured why not just call the aws command line tool from R. processx is an insane package that might be the mother of all packages. It allows you to run command line tools from R with flexibility for some things like setting the directory where the command is called from in the processx called function (big deal as far as I can tell).\nWe need to set up our aws account online. The blog above from Danielle Navarro covers that I believe (I struggled through it a long time ago). I should use a ~/.aws/credentials file but don‚Äôt yet. I have my credentials in my ~/.Renviron file as well as in my ~/.bash_profile (probably a ridiculous setup). They are:\nAWS_ACCESS_KEY_ID='my_key'\nAWS_DEFAULT_REGION='my_region'\nAWS_SECRET_ACCESS_KEY='my_secret_key'\n\n\nCode\n# library(aws.s3)\nlibrary(processx)\n# library(paws) #this is the mom.  Couple examples of us hashed out here\nlibrary(s3fs)\n# library(aws.iam) #not useing - set permissions\nlibrary(here) #helps us with working directory issues related to the `environment` we operate in when rendering\n\n\n\nSee buckets using the s3fs package.\n\nCurrent buckets are:\n\n\nCode\ns3fs::s3_dir_ls(refresh = TRUE) \n\n\n[1] \"s3://23cog\"\n\n\n\n\nCode\n# First we set up our AWS s3 file system. I am actually not sure this is necessary but I did it.  Will turn the chunk off\n# to not repeat.\n# s3fs::s3_file_system(profile_name = \"s3fs_example\")\n\n\n\n\nCreate a Bucket\nLet‚Äôs generate the name of the bucket based on the name of the repo but due to aws bucket naming rules we need to swap out our underscores for hyphens! Maybe a good enough reason to change our naming conventions for our repos on github!!\n\n\nCode\nbucket_name &lt;- basename(here::here()) |&gt; \n  stringr::str_replace_all(\"_\", \"-\") \n\nbucket_path &lt;- s3fs::s3_path(bucket_name)\n\ns3fs::s3_bucket_create( bucket_path)  \n\n\n[1] \"s3://new-graphiti\"\n\n\n\n\nSync Files to Bucket\nWe build a little wrapper function to help us debug issues when running system commands with processx.\n\n\nCode\nsys_call &lt;- function(){\n  result &lt;- tryCatch({\n    processx::run(\n      command,\n      args = args,\n      echo = TRUE,            # Print the command output live\n      wd = working_directory, # Set the working directory\n      spinner = TRUE,         # Show a spinner\n      timeout = 60            # Timeout after 60 seconds\n    )\n  }, error = function(e) {\n    # Handle errors: e.g., print a custom error message\n    cat(\"An error occurred: \", e$message, \"\\n\")\n    NULL  # Return NULL or another appropriate value\n  })\n  \n  # Check if the command was successful\n  if (!is.null(result)) {\n    cat(\"Exit status:\", result$status, \"\\n\")\n    cat(\"Output:\\n\", result$stdout)\n  } else {\n    cat(\"Failed to execute the command properly.\\n\")\n  }\n}\n\n\n\nThen we specify our command and arguments. To achieve the desired behavior of including only files in the assets/* directory, you need to combine the order of --exclude and --include flags appropriately (exclude everything first thenn include what we want):\n\n\nCode\ncommand &lt;- \"aws\"\nargs &lt;- c('s3', 'sync', '.', bucket_path, '--delete', '--exclude', '*', '--include', 'posts/*')\n\nworking_directory = here::here() #we could just remove from funciton to get the current wd but its nice to have so we leave\n\n\nNow lets put a tester file in our directory and sync it to our bucket. We will remove it later to test if it is removed on sync.\n\n\nCode\nfile.create(here::here('posts/test.txt'))\n\n\n[1] TRUE\n\n\nRun our little function to sync the files to the bucket.\n\n\nCode\nsys_call()\n\n\nCompleted 237 Bytes/511.7 KiB (3.0 KiB/s) with 12 file(s) remaining\nupload: posts/_metadata.yml to s3://new-graphiti/posts/_metadata.yml\nCompleted 237 Bytes/511.7 KiB (3.0 KiB/s) with 11 file(s) remaining\nCompleted 2.0 KiB/511.7 KiB (11.9 KiB/s) with 11 file(s) remaining \nupload: posts/logos-equipment/index.qmd to s3://new-graphiti/posts/logos-equipment/index.qmd\nCompleted 2.0 KiB/511.7 KiB (11.9 KiB/s) with 10 file(s) remaining\nCompleted 3.6 KiB/511.7 KiB (20.8 KiB/s) with 10 file(s) remaining\nupload: posts/snakecase/index.qmd to s3://new-graphiti/posts/snakecase/index.qmd\nCompleted 3.6 KiB/511.7 KiB (20.8 KiB/s) with 9 file(s) remaining\nCompleted 8.6 KiB/511.7 KiB (48.5 KiB/s) with 9 file(s) remaining\nupload: posts/snakecase/thumbnail.jpg to s3://new-graphiti/posts/snakecase/thumbnail.jpg\nCompleted 8.6 KiB/511.7 KiB (48.5 KiB/s) with 8 file(s) remaining\nCompleted 13.9 KiB/511.7 KiB (74.3 KiB/s) with 8 file(s) remaining\nupload: posts/aws-storage-permissions/index.qmd to s3://new-graphiti/posts/aws-storage-permissions/index.qmd\nCompleted 13.9 KiB/511.7 KiB (74.3 KiB/s) with 7 file(s) remaining\nCompleted 17.8 KiB/511.7 KiB (82.4 KiB/s) with 7 file(s) remaining\nupload: posts/aws-storage-processx/image.jpg to s3://new-graphiti/posts/aws-storage-processx/image.jpg\nCompleted 17.8 KiB/511.7 KiB (82.4 KiB/s) with 6 file(s) remaining\nupload: posts/test.txt to s3://new-graphiti/posts/test.txt        \nCompleted 17.8 KiB/511.7 KiB (82.4 KiB/s) with 5 file(s) remaining\nCompleted 26.0 KiB/511.7 KiB (119.1 KiB/s) with 5 file(s) remaining\nupload: posts/aws-storage-processx/index.rmarkdown to s3://new-graphiti/posts/aws-storage-processx/index.rmarkdown\nCompleted 26.0 KiB/511.7 KiB (119.1 KiB/s) with 4 file(s) remaining\nCompleted 34.0 KiB/511.7 KiB (152.0 KiB/s) with 4 file(s) remaining\nupload: posts/aws-storage-permissions/image.jpg to s3://new-graphiti/posts/aws-storage-permissions/image.jpg\nCompleted 34.0 KiB/511.7 KiB (152.0 KiB/s) with 3 file(s) remaining\nCompleted 42.2 KiB/511.7 KiB (180.5 KiB/s) with 3 file(s) remaining\nupload: posts/aws-storage-processx/index.qmd to s3://new-graphiti/posts/aws-storage-processx/index.qmd\nCompleted 42.2 KiB/511.7 KiB (180.5 KiB/s) with 2 file(s) remaining\nCompleted 83.0 KiB/511.7 KiB (256.0 KiB/s) with 2 file(s) remaining\nupload: posts/logos-equipment/image.jpg to s3://new-graphiti/posts/logos-equipment/image.jpg\nCompleted 83.0 KiB/511.7 KiB (256.0 KiB/s) with 1 file(s) remaining\nCompleted 339.0 KiB/511.7 KiB (830.9 KiB/s) with 1 file(s) remaining\nCompleted 511.7 KiB/511.7 KiB (654.4 KiB/s) with 1 file(s) remaining\nupload: posts/snakecase/all.jpeg to s3://new-graphiti/posts/snakecase/all.jpeg\nExit status: 0 \nOutput:\n Completed 237 Bytes/511.7 KiB (3.0 KiB/s) with 12 file(s) remaining\nupload: posts/_metadata.yml to s3://new-graphiti/posts/_metadata.yml\nCompleted 237 Bytes/511.7 KiB (3.0 KiB/s) with 11 file(s) remaining\nCompleted 2.0 KiB/511.7 KiB (11.9 KiB/s) with 11 file(s) remaining \nupload: posts/logos-equipment/index.qmd to s3://new-graphiti/posts/logos-equipment/index.qmd\nCompleted 2.0 KiB/511.7 KiB (11.9 KiB/s) with 10 file(s) remaining\nCompleted 3.6 KiB/511.7 KiB (20.8 KiB/s) with 10 file(s) remaining\nupload: posts/snakecase/index.qmd to s3://new-graphiti/posts/snakecase/index.qmd\nCompleted 3.6 KiB/511.7 KiB (20.8 KiB/s) with 9 file(s) remaining\nCompleted 8.6 KiB/511.7 KiB (48.5 KiB/s) with 9 file(s) remaining\nupload: posts/snakecase/thumbnail.jpg to s3://new-graphiti/posts/snakecase/thumbnail.jpg\nCompleted 8.6 KiB/511.7 KiB (48.5 KiB/s) with 8 file(s) remaining\nCompleted 13.9 KiB/511.7 KiB (74.3 KiB/s) with 8 file(s) remaining\nupload: posts/aws-storage-permissions/index.qmd to s3://new-graphiti/posts/aws-storage-permissions/index.qmd\nCompleted 13.9 KiB/511.7 KiB (74.3 KiB/s) with 7 file(s) remaining\nCompleted 17.8 KiB/511.7 KiB (82.4 KiB/s) with 7 file(s) remaining\nupload: posts/aws-storage-processx/image.jpg to s3://new-graphiti/posts/aws-storage-processx/image.jpg\nCompleted 17.8 KiB/511.7 KiB (82.4 KiB/s) with 6 file(s) remaining\nupload: posts/test.txt to s3://new-graphiti/posts/test.txt        \nCompleted 17.8 KiB/511.7 KiB (82.4 KiB/s) with 5 file(s) remaining\nCompleted 26.0 KiB/511.7 KiB (119.1 KiB/s) with 5 file(s) remaining\nupload: posts/aws-storage-processx/index.rmarkdown to s3://new-graphiti/posts/aws-storage-processx/index.rmarkdown\nCompleted 26.0 KiB/511.7 KiB (119.1 KiB/s) with 4 file(s) remaining\nCompleted 34.0 KiB/511.7 KiB (152.0 KiB/s) with 4 file(s) remaining\nupload: posts/aws-storage-permissions/image.jpg to s3://new-graphiti/posts/aws-storage-permissions/image.jpg\nCompleted 34.0 KiB/511.7 KiB (152.0 KiB/s) with 3 file(s) remaining\nCompleted 42.2 KiB/511.7 KiB (180.5 KiB/s) with 3 file(s) remaining\nupload: posts/aws-storage-processx/index.qmd to s3://new-graphiti/posts/aws-storage-processx/index.qmd\nCompleted 42.2 KiB/511.7 KiB (180.5 KiB/s) with 2 file(s) remaining\nCompleted 83.0 KiB/511.7 KiB (256.0 KiB/s) with 2 file(s) remaining\nupload: posts/logos-equipment/image.jpg to s3://new-graphiti/posts/logos-equipment/image.jpg\nCompleted 83.0 KiB/511.7 KiB (256.0 KiB/s) with 1 file(s) remaining\nCompleted 339.0 KiB/511.7 KiB (830.9 KiB/s) with 1 file(s) remaining\nCompleted 511.7 KiB/511.7 KiB (654.4 KiB/s) with 1 file(s) remaining\nupload: posts/snakecase/all.jpeg to s3://new-graphiti/posts/snakecase/all.jpeg\n\n\nThen we can see our bucket contents - as well as list our bucket contents and capture them.\n\n\nCode\ns3fs::s3_dir_tree(bucket_path)\n\n\ns3://new-graphiti\n‚îî‚îÄ‚îÄ posts\n    ‚îú‚îÄ‚îÄ _metadata.yml\n    ‚îú‚îÄ‚îÄ test.txt\n    ‚îú‚îÄ‚îÄ aws-storage-permissions\n    ‚îÇ   ‚îú‚îÄ‚îÄ image.jpg\n    ‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n    ‚îú‚îÄ‚îÄ aws-storage-processx\n    ‚îÇ   ‚îú‚îÄ‚îÄ image.jpg\n    ‚îÇ   ‚îú‚îÄ‚îÄ index.qmd\n    ‚îÇ   ‚îî‚îÄ‚îÄ index.rmarkdown\n    ‚îú‚îÄ‚îÄ logos-equipment\n    ‚îÇ   ‚îú‚îÄ‚îÄ image.jpg\n    ‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n    ‚îî‚îÄ‚îÄ snakecase\n        ‚îú‚îÄ‚îÄ all.jpeg\n        ‚îú‚îÄ‚îÄ index.qmd\n        ‚îî‚îÄ‚îÄ thumbnail.jpg\n\n\nCode\nt &lt;- s3fs::s3_dir_info(bucket_path, recurse = TRUE)\n\n\nNow we will remove test.txt\n\n\nCode\nfile.remove(here::here('posts/test.txt'))\n\n\n[1] TRUE\n\n\nNow we sync again.\n\n\nCode\nsys_call()\n\n\ndelete: s3://new-graphiti/posts/test.txt\nExit status: 0 \nOutput:\n delete: s3://new-graphiti/posts/test.txt\n\n\nList our bucket contents and capture them again\n\n\nCode\ns3_dir_tree(bucket_path)\n\n\ns3://new-graphiti\n‚îî‚îÄ‚îÄ posts\n    ‚îú‚îÄ‚îÄ _metadata.yml\n    ‚îú‚îÄ‚îÄ aws-storage-permissions\n    ‚îÇ   ‚îú‚îÄ‚îÄ image.jpg\n    ‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n    ‚îú‚îÄ‚îÄ aws-storage-processx\n    ‚îÇ   ‚îú‚îÄ‚îÄ image.jpg\n    ‚îÇ   ‚îú‚îÄ‚îÄ index.qmd\n    ‚îÇ   ‚îî‚îÄ‚îÄ index.rmarkdown\n    ‚îú‚îÄ‚îÄ logos-equipment\n    ‚îÇ   ‚îú‚îÄ‚îÄ image.jpg\n    ‚îÇ   ‚îî‚îÄ‚îÄ index.qmd\n    ‚îî‚îÄ‚îÄ snakecase\n        ‚îú‚îÄ‚îÄ all.jpeg\n        ‚îú‚îÄ‚îÄ index.qmd\n        ‚îî‚îÄ‚îÄ thumbnail.jpg\n\n\nCode\nt2 &lt;- s3fs::s3_dir_info(bucket_path, recurse = TRUE)\n\n\nCompare the file structure before and after our sync.\n\n\nCode\nwaldo::compare(t$key, t2$key)\n\n\n     old                             | new                                 \n [9] \"posts/snakecase/all.jpeg\"      | \"posts/snakecase/all.jpeg\"      [9] \n[10] \"posts/snakecase/index.qmd\"     | \"posts/snakecase/index.qmd\"     [10]\n[11] \"posts/snakecase/thumbnail.jpg\" | \"posts/snakecase/thumbnail.jpg\" [11]\n[12] \"posts/test.txt\"                -                                     \n\n\nSuccess!!\n\n\nTo Do\nWe need to build the call to sync the other way (cloud to local) in a way that perhaps nukes local files if they are not on the cloud. This is because we need to collaborate within our team so we do things like one person will change the name of images so when the other person syncs they will have only the newly named image in their local directory.\n\nThis all deserved consideration as it could get really messy from a few different angles (ie. one person adds files they don‚Äôt want nuked and then they get nukes. There are lots of different options for doing things so we will get there.)\n\n\nDelete Bucket\nLets delete the bucket.\n\n\nCode\n#\nHere is the command line approach that we will turn off in favor of the s3fs approach.\nargs &lt;- c('s3', 'rb', bucket_path, '--force')\nsys_call()\n\n\n\n\nCode\n# Here is the `s3fs` way to \"delete\" all the versions.  \n# list all the files in the bucket\nfl &lt;- s3fs::s3_dir_ls(bucket_path, recurse = TRUE, refresh = TRUE)\n\n# list all the version info for all the files\nvi &lt;- fl |&gt; \n  purrr::map_df(s3fs::s3_file_version_info)\n\ns3fs::s3_file_delete(path = vi$uri)\n\n\n\n\nCode\ns3fs::s3_bucket_delete(bucket_path)\n\n\n[1] \"s3://new-graphiti\"\n\n\nAs we have tried this before we know that if we tell it we want to delete a bucket with versioned files in it we need to empty the bucket first including delete_markers. That is easy in the aws console with th UI but seems tricky. There is a bunch of discussion on options to this here https://stackoverflow.com/questions/29809105/how-do-i-delete-a-versioned-bucket-in-aws-s3-using-the-cli . Thinking a good way around it (and a topic for another post) would be to apply a lifecycle-configuration to the bucket that deletes all versions of files after a day - allowing you to delete bucket after they expire (as per the above post). Really we may want to have a lifecycle-configuration on all our versioned buckets to keep costs down anyway but deserves more thought and perhaps another post.\n\n\nCode\n# old notes\n# We are going to test creating a bucket with versioning on.  This has large implications for billing with some details\n# of how it works [here](https://aws.amazon.com/blogs/aws/amazon-s3-enhancement-versioning/) with example of costs [here](https://aws.amazon.com/s3/faqs/?nc1=h_ls).  Thinking we may want versioned buckets for things like `sqlite`\n# \"snapshot\" databases but definitely not for things like images."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "new graphiti",
    "section": "",
    "text": "Setting aws bucket permissions with R\n\n\n\n\n\n\nnews\n\n\nassets\n\n\naws\n\n\ns3\n\n\nr\n\n\npaws\n\n\n\n\n\n\n\n\n\nMay 24, 2024\n\n\nal\n\n\n\n\n\n\n\n\n\n\n\n\nSyncing files to aws with R\n\n\n\n\n\n\nnews\n\n\nassets\n\n\naws\n\n\ns3\n\n\nr\n\n\npaws\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\nal\n\n\n\n\n\n\n\n\n\n\n\n\nsnake_case vs Everything_Else\n\n\n\n\n\n\nnames\n\n\nnews\n\n\n\n\n\n\n\n\n\nMay 7, 2024\n\n\nal\n\n\n\n\n\n\n\n\n\n\n\n\nLogos and Equipment List Somewhere Accessible\n\n\n\n\n\n\nnews\n\n\nassets\n\n\n\n\n\n\n\n\n\nMay 7, 2024\n\n\nal\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "rws",
    "section": "",
    "text": "raNdom workish stufF"
  },
  {
    "objectID": "posts/snakecase/index.html",
    "href": "posts/snakecase/index.html",
    "title": "snake_case vs Everything_Else",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = \"100%\")\noptions(scipen=999)\noptions(knitr.kable.NA = '--') #'--'\noptions(knitr.kable.NAN = '--')\n\n\nBeen preferring snakecase naming convention for all files and columns and variables for a long time for the following reasons:\n\nIt‚Äôs much easier to type. Reaching for the shift button is a pain.\nArguably easier to read. I find it easier to read snake_case than CamelCase.\nCan make it easy to name things in a fashion that allows you to dissect, what, something, is by the way it is named and allows automatic sorting to group similar things together. This presentation by Jenny Bryan is a good read - https://speakerdeck.com/jennybc/how-to-name-files-the-sequel.\n\n\n\nCode\nknitr::include_graphics(\"thumbnail.jpg\")\n\n\n\n\n\n\n\n\nFigure¬†1\n\n\n\n\n\nWorth noting that sometimes-rules-need-to-be-broken sometimes such as when you are naming chunks in Rmarkdown. It breaks our cross-references.\n\nAs we see here though - it doesn‚Äôt matter in Quarto (ex. see Figure¬†1) vs Figure¬†2).\n\n\nCode\nknitr::include_graphics(\"all.jpeg\")\n\n\n\n\n\n\n\n\nFigure¬†2\n\n\n\n\n\n\n‚Äúno names have an anonymous function‚Äù.\n¬†¬†¬†¬†-Michael Sumner"
  },
  {
    "objectID": "posts/logos-equipment/index.html",
    "href": "posts/logos-equipment/index.html",
    "title": "Logos and Equipment List Somewhere Accessible",
    "section": "",
    "text": "Code\nknitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, dpi=60, out.width = \"100%\")\noptions(scipen=999)\noptions(knitr.kable.NA = '--') #'--'\noptions(knitr.kable.NAN = '--')\n\n\nThis here is a post showing where we are now keeping the company equipment details as well as the company logos. We need these things to be accessible to all team members from all repos so we have put them here since this is a public repo.\nHere is the location of the equipment lists that we use in safety/field planning:\nhttps://raw.githubusercontent.com/NewGraphEnvironment/new_graphiti/main/assets/data/equipment.csv\n\n\nCode\nreadr::read_csv(\n  url(\n    glue::glue(\"https://raw.githubusercontent.com/{params$repo_owner}/{params$repo_name}/main/assets/data/equipment.csv\")\n  )\n)|&gt; \n  fpr::fpr_kable(font = 12)\n\n\n\n\n\n\n\n\neq_item\neq_pers_standard\neq_truck\neq_safety\neq_task1\neq_task2\neq_task3\neq_task4\neq_task5\neq_task6\neq_task7\nmateo_winterschedt\n\n\n\n\nclinometer\nx\n--\n--\nall\nelectrofishing\nfish passage\n--\n--\n--\n--\nx\n\n\nfield vest\nx\n--\n--\nall\n--\nfish passage\n--\n--\n--\n--\nx\n\n\nnote book\nx\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nGPS\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\nx\n\n\nSuncreen\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nBugspray\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nPolarized glasses\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nBear Spray\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\nx\n\n\nphone/camera\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nbattery pack booster for phone\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nHat\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nfirst aid kit personal\nx\n--\nx\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nWaders\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\nx\n\n\nBoots\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\nx\n\n\nExtra clothes\nx\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nrain gear\nx\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nSki poles\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nwater\nx\n--\nx\nall\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nfood\nx\n--\nx\nall\n--\nfish passage\n--\n--\n--\n--\n--\n\n\ngloves work\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nglasses safety\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nheadlamp\nx\n--\nx\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nOakton Multimeter\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\nTurbidity Meter LaMotte 2020e\n--\n--\n--\n--\n--\n--\nenvironmental monitoring\nwq\n--\n--\n--\n\n\nHand saw\n--\nx\nx\nall\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\nBackpack Electrofisher\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\nstop nets x 4\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\nsalt blocks\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\nloose salt\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\ndip nets x 2\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\nLinesman Gloves x 3\n--\n--\nx\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\ntape measure hand\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\ntape measure eslon\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\npilon x 2\n--\nx\n--\nall\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nMeasuring board\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nScale\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nPermits\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nBackroads Mapbook\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nLocational maps\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nFish ID book\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nBackground Documents\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nradio handheld\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nradio truck\n--\nx\n--\n--\n--\n--\n--\n--\n--\n--\nx\n\n\nradio chargers x 3\n--\n--\nx\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nSatelite communicator\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nField Safety Plan\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nfirst aid kit level 1\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nFirst Aid binder stocked\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nSite Cards / Field Guide\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nMinnow Traps\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nCatfood\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nFlagging\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nLaptop w/basecamp\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nGPS cable\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nLazer level\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nAssessment cards fish passage\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nUAV radio\n--\n--\nx\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nUAV\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nUAV landing pad\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nUAV GC tape\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nUAV safety plan (when required)\n--\n--\nx\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nUAV registration\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nUAV license\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nUAV radio license\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nFlow meter\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nATV\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nThrow bags\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\npolaski\n--\nx\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nshovel\n--\nx\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nfire extinguisher backpack\n--\nx\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nfire extinguisher pressurized\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nbucket rigid x 2\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nbucket foldable\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nclove oil kit w/ instructions\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\ngloves leather\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nhard hat\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nsteel toed boots\nx\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nsharpies\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nhand lens\nx\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nATV gas\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nATV lock\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nUAV battery charger\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nwader disinfectant kit\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\ntruck tow rope\n--\nx\nx\nall\n--\n--\n--\n--\n--\n--\n--\n\n\ntruck jack\n--\nx\nx\nall\n--\n--\n--\n--\n--\n--\n--\n\n\nGPS batteries\n--\n--\n--\n--\nelectrofishing\nfish passage\n--\n--\n--\n--\n--\n\n\nATV helmets\n--\n--\n--\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nBattery booster\n--\nx\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nCompressor 12V\n--\nx\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nRubber boots (no-slip soles)\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nSmall BT Speaker (for bears)\n--\n--\nx\n--\n--\nfish passage\n--\n--\n--\n--\n--\n\n\nGPS Case waterproof\n--\n--\n--\nsnorkling\n--\n--\n--\n--\n--\n--\n--\n\n\nNotebook waterproof\n--\n--\n--\nsnorkling\n--\n--\n--\n--\n--\n--\n--\n\n\nDrysuits\n--\n--\n--\nsnorkling\n--\n--\n--\n--\n--\n--\n--\n\n\nSnorkels\n--\n--\n--\nsnorkling\n--\n--\n--\n--\n--\n--\n--\n\n\ndrysuit gloves\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nGoggles\n--\n--\n--\nsnorkling\n--\n--\n--\n--\n--\n--\n--\n\n\nFanny pack\n--\n--\n--\nsnorkling\n--\n--\n--\n--\n--\n--\n--\n\n\nlarge backpack\n--\n--\n--\n--\nelectrofishing\n--\n--\n--\n--\n--\n--\n\n\nTow strap\n--\nx\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\nrange finder\nx\n--\n--\n--\n--\n--\n--\n--\n--\n--\n--\n\n\n\n\n\n\n\n\n\n\nLogos:\nhttps://raw.githubusercontent.com/NewGraphEnvironment/new_graphiti/main/assets/logos\nThere are many ‚Äî so here is a list of their names and locations online:\n\n\nCode\nfile_names &lt;- fs::dir_ls(\n  glue::glue(here::here(\"assets/logos\")),\n  glob = c(\"*.png\", \"*.jpg\", \"*.jpeg\"),\n  recurse = TRUE\n) \n\n\ntibble::tibble(path = file_names) |&gt; \n    dplyr::mutate(path = stringr::str_replace_all(path, \"/Users/airvine/Projects/repo/new_graphiti\", \"https://github.com/NewGraphEnvironment/new_graphiti/tree/main\")) |&gt; \n  fpr::fpr_kable(font = 12)\n\n\n\n\n\n\n\n\npath\n\n\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/BLACK/PNG/nge-full_black.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/BLACK/PNG/nge-icon_black.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/BLACK/PNG/nge-icon_name_big_black.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/BLACK/PNG/nge-icon_name_black.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/BLACK/PNG/nge-name_black.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/BLACK/PNG/nge-name_research_consulting_black.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/BLACK/PNG/nge-research_consulting_black.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/COLOR/PNG/nge-full_color.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/COLOR/PNG/nge-icon.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/COLOR/PNG/nge-icon_name.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/COLOR/PNG/nge-icon_name_big_color.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/COLOR/PNG/nge-name_color.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/COLOR/PNG/nge-name_research_consulting_color.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/COLOR/PNG/nge-research_consulting_color.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/GREYSCALE/PNG/nge-full_greyscale.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/GREYSCALE/PNG/nge-icon_gradient_grey.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/GREYSCALE/PNG/nge-icon_name_big_greyscale.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/GREYSCALE/PNG/nge-icon_name_greyscale.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/GREYSCALE/PNG/nge-name_greyscale.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/GREYSCALE/PNG/nge-name_research_consulting_greyscale.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/GREYSCALE/PNG/nge-research_consulting_greyscale.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/WHITE/PNG/nge-full_white.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/WHITE/PNG/nge-icon_name_big_white.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/WHITE/PNG/nge-icon_name_white.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/WHITE/PNG/nge-icon_white.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/WHITE/PNG/nge-name_research_consulting_white.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/WHITE/PNG/nge-name_white.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/logo_newgraph/WHITE/PNG/nge-research_consulting_white.png\n\n\nhttps://github.com/NewGraphEnvironment/new_graphiti/tree/main/assets/logos/pixel.png"
  }
]